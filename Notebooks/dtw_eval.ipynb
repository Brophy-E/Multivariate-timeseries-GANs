{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "dtw_eval.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jNAoQ34FzHIJ"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zILHI4yR6J1"
      },
      "source": [
        "# Multivariate Time Series Generation - MVDTW Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sG4nuHrTA6x"
      },
      "source": [
        "## If Using Google Colabs\n",
        "\n",
        "Mount your drive if you are running this on Colabs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JISJWy1TB8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230757c9-cded-415e-820e-22b0abdf001a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcraGNzJTHG7"
      },
      "source": [
        "## Directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkS81dADTKdg"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/MV_GAN_Journal/Multivariate_time_series_gen/')\n",
        "path = '/content/drive/My Drive/MV_GAN_Journal/Multivariate_time_series_gen/'\n",
        "\n",
        "data_dir = './Data'\n",
        "results_dir = './Results/your_result_dir'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlhpBij_TNZ7"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh7ZIiGER6J4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import json as js\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from model import Generator\n",
        "\n",
        "from torch.autograd.variable import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqrNk02NTTWs"
      },
      "source": [
        "For Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckc9YZu7TVaj"
      },
      "source": [
        "# Colour Blind Friendly Colours\n",
        "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
        "                  '#f781bf', '#a65628', '#984ea3',\n",
        "                  '#999999', '#e41a1c', '#dede00']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNAoQ34FzHIJ"
      },
      "source": [
        "### R package for fast MVDTW execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlIEo5NEwMU8"
      },
      "source": [
        "import rpy2.robjects.numpy2ri\n",
        "from rpy2.robjects.packages import importr\n",
        "rpy2.robjects.numpy2ri.activate()\n",
        "import rpy2.robjects as robj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVmZfqX5wPFj",
        "outputId": "27d9e6a8-4aec-44fc-abee-2e0f0ccb05f0"
      },
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
            "  from pandas.core.index import Index as PandasIndex\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n",
            "  warnings.warn('pandas >= 1.0 is not supported.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srsgz3BPwQTB"
      },
      "source": [
        "%%R\n",
        "install.packages(\"dtw\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMoDDPCZwZ28"
      },
      "source": [
        "# Set up our R namespaces\n",
        "R = rpy2.robjects.r\n",
        "DTW = importr('dtw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHWurW6rTc7w"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtGxs-x7R6KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da436ab1-0876-4758-a413-d779d070097c"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  cuda = True\n",
        "  print('Using: ' +str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "  cuda = False\n",
        "  print('Using: CPU')\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o08aRs3DTiEz"
      },
      "source": [
        "## Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iE28iLlR6KD"
      },
      "source": [
        "def load_gen(file):\n",
        "    gen = torch.load(file)\n",
        "    return gen\n",
        "\n",
        "def noise(batch_size, features):\n",
        "    noise_vec = torch.randn(2, batch_size, features).to(device)\n",
        "    return noise_vec\n",
        "\n",
        "def uni_noise(batch_size, features):\n",
        "    noise_vec = torch.randn(batch_size, features).to(device)\n",
        "    return noise_vec\n",
        "\n",
        "def load_params(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        param_dict = js.load(f)\n",
        "    \n",
        "    return param_dict\n",
        "\n",
        "def load_data(filename, batch_size):\n",
        "    mv_data = torch.load(filename)\n",
        "    if len(mv_data[0,:,0]) == 501:\n",
        "        mv_data = mv_data[:, :-1, :] \n",
        "    data_loader = torch.utils.data.DataLoader(mv_data, batch_size=batch_size)\n",
        "    num_batches = len(data_loader)\n",
        "    \n",
        "    return data_loader, num_batches "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmS3ilifR6KJ"
      },
      "source": [
        "def load_single_gen(file, params):\n",
        "    generator  = Generator(params['seq_len'], params['batch_size'], hidden_dim=params['hidden_nodes_g'], num_layers=params['layers'], \n",
        "                           tanh_output=params['tanh_layer']).to(device)\n",
        "    generator.load_state_dict(torch.load(file))\n",
        "    generator.eval()\n",
        "    h_g = generator.init_hidden()\n",
        "    \n",
        "    # generate noise\n",
        "    test_noise_sample = noise(params['batch_size'], params['seq_len'])\n",
        "    # generate batch of data\n",
        "    gen_data = generator.forward(test_noise_sample,h_g).detach()\n",
        "    \n",
        "    return gen_data, test_noise_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfZJXmAsR6KL"
      },
      "source": [
        "## DTW_d Programatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTDMb3K3xF74"
      },
      "source": [
        "from numba.typed import List\n",
        "from numba import njit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fhB2HsHR6KM"
      },
      "source": [
        "def distance_matrix(Q, C):\n",
        "    matrix = np.ones((len(C), len(Q)))\n",
        "    for i in range(len(C)):\n",
        "        for j in range(len(Q)):\n",
        "            matrix[i,j] = (Q[j] - C[i])**2\n",
        "    distances = np.asmatrix(matrix)\n",
        "    \n",
        "    return distances\n",
        "\n",
        "\n",
        "## Plot the Distance Cost Plot\n",
        "def distance_cost_plot(distances):\n",
        "    im = plt.imshow(distances, interpolation='nearest', cmap='Reds') \n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.grid()\n",
        "    plt.colorbar();\n",
        "\n",
        "def accumulated_costs(Q,C, distances):\n",
        "    accumulated_cost = np.zeros((len(C), len(Q)))\n",
        "    accumulated_cost[0,0] = distances[0,0]\n",
        "    \n",
        "    # First Row Only\n",
        "    for i in range(1, len(Q)):\n",
        "        accumulated_cost[0,i] = distances[0,i] + accumulated_cost[0, i-1]\n",
        "    # First Column Only\n",
        "    for i in range(1, len(C)):\n",
        "        accumulated_cost[i,0] = distances[i, 0] + accumulated_cost[i-1, 0]\n",
        "    # All other Elements\n",
        "    for i in range(1, len(C)):\n",
        "        for j in range(1, len(Q)):\n",
        "            accumulated_cost[i, j] = min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]) + distances[i, j]\n",
        "    \n",
        "    return accumulated_cost\n",
        "\n",
        "def backtrack(Q, C, accumulated_cost, plotting=True):\n",
        "    path = [[len(Q)-1, len(C)-1]]\n",
        "    i = len(C)-1\n",
        "    j = len(Q)-1\n",
        "    while i>0 and j>0:\n",
        "        if i==0:\n",
        "            j = j - 1\n",
        "        elif j==0:\n",
        "            i = i - 1\n",
        "        else:\n",
        "            if accumulated_cost[i-1, j] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n",
        "                i = i - 1\n",
        "            elif accumulated_cost[i, j-1] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n",
        "                j = j-1\n",
        "            else:\n",
        "                i = i - 1\n",
        "                j= j- 1\n",
        "        path.append([j, i])\n",
        "    path.append([0,0])\n",
        "\n",
        "    path_x = [point[0] for point in path]\n",
        "    path_y = [point[1] for point in path]\n",
        "\n",
        "  \n",
        "    #if plotting == True:\n",
        "    #    distance_cost_plot(accumulated_cost)\n",
        "    #    plt.plot(path_x, path_y)\n",
        "\n",
        "    return path\n",
        "\n",
        "def path_cost(Q, C, accumulated_cost, distances):\n",
        "    path = [[len(Q)-1, len(C)-1]]\n",
        "    cost = 0\n",
        "    i = len(C)-1\n",
        "    j = len(Q)-1\n",
        "    while i>0 and j>0:\n",
        "        if i==0:\n",
        "            j = j - 1\n",
        "        elif j==0:\n",
        "            i = i - 1\n",
        "        else:\n",
        "            if accumulated_cost[i-1, j] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n",
        "                i = i - 1\n",
        "            elif accumulated_cost[i, j-1] == min(accumulated_cost[i-1, j-1], accumulated_cost[i-1, j], accumulated_cost[i, j-1]):\n",
        "                j = j-1\n",
        "            else:\n",
        "                i = i - 1\n",
        "                j= j- 1\n",
        "        path.append([j, i])\n",
        "    path.append([0,0])\n",
        "\n",
        "    for [C, Q] in path:\n",
        "        cost = cost +distances[Q, C]\n",
        "\n",
        "    return(path, cost)\n",
        "\n",
        "def distance_DTWd(Q, C):\n",
        "    matrix = np.ones((len(C[0]), len(Q[0])))\n",
        "    for i in range(len(C[0])):\n",
        "        for j in range(len(Q[0])):\n",
        "            d = 0\n",
        "            for M in range(len(Q)):\n",
        "                d += ((Q[M][j] - C[M][i])**2)\n",
        "            matrix[i,j] = d\n",
        "  \n",
        "    distances = np.asmatrix(matrix)\n",
        "    return distances\n",
        "\n",
        "def DTW_i(Q, C):\n",
        "    c = 0\n",
        "    p = []\n",
        "    for i in range(len(Q)):\n",
        "        distance =  distance_matrix(Q[i], C[i])\n",
        "        acc_costs = accumulated_costs(Q[i],C[i],distance)\n",
        "        path = backtrack(Q[i],C[i], acc_costs, plotting=False)\n",
        "        paths, cost = path_cost(Q[i], C[i], acc_costs, distance)\n",
        "        c += cost\n",
        "    return(c)\n",
        "\n",
        "def DTW_d(Q, C):\n",
        "    c = []\n",
        "    p = []\n",
        "    for i in range(len(Q)):\n",
        "        distance = distance_DTWd(Q,C)\n",
        "        acc_costs = accumulated_costs(Q[i],C[i],distance)\n",
        "        path = backtrack(Q[i],C[i], acc_costs, plotting=False)\n",
        "        paths, cost = path_cost(Q[i], C[i], acc_costs, distance)\n",
        "        c.append(cost)\n",
        "\n",
        "    return(np.min(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzTwEpUyR6KN"
      },
      "source": [
        "def evaluate_dtw_sample(gen, real):\n",
        "    d=[]\n",
        "    for i in tqdm(range(len(real))):\n",
        "        #for j in range(len(gen)):\n",
        "            sample = real[i].permute(1,0)\n",
        "            gen_data = gen[i].permute(1,0)\n",
        "            # Compute DTW_d\n",
        "            d.append(DTW_d(gen_data.detach().cpu().numpy(), sample.detach().cpu().numpy()))\n",
        "            # Option for DTW_i\n",
        "            #d.append(DTW_i(gen_data.detach().cpu().numpy(), sample.detach().cpu().numpy()))\n",
        "    D = np.mean(d)\n",
        "    \n",
        "    return D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAZdRqEIR6KP"
      },
      "source": [
        "def run_DTW_d(data_dir, results_dir, params): \n",
        "    data_loader, num_batches = load_data(data_dir+'/'+params['data'], params['batch_size'])\n",
        "    MBD_dtw=[]\n",
        "    print('data_loaded')\n",
        "    # Iterate through MBD layers\n",
        "    for mb in params['minibatch_layer']:\n",
        "        print(\"MBD_Layer: \"+str(mb))\n",
        "        D = []\n",
        "        # Generate batch of data for every epoch\n",
        "        for e in tqdm(range(0,params['epochs'])):\n",
        "            file = (results_dir+'/MBD_'+str(mb)+'/gen/generator_state_%s.pt'%(e)) \n",
        "            gen_data, sample_noise = load_single_gen(file, params)\n",
        "            # Compare Generated Data against every batch\n",
        "            dtw_result = []\n",
        "            random_int = np.random.randint(low = 1, high=num_batches-1)\n",
        "            for n_batch, sample_data in enumerate(data_loader):\n",
        "                if n_batch == random_int:\n",
        "                    # compute dtw for every batch against our generated data\n",
        "                    dtw_result.append(evaluate_dtw_sample(gen_data[:1,:,:], sample_data[:1,:,:]))\n",
        "            # mean of dtw for this epoch\n",
        "            D.append(np.mean(dtw_result))\n",
        "        MBD_dtw.append(D)\n",
        "    return MBD_dtw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqDTdsK6zcVq"
      },
      "source": [
        "If you want to run just one evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdXb_oF3TnMo"
      },
      "source": [
        "def run_DTW_d_short(data_dir, results_dir, params): \n",
        "\n",
        "    data_loader, num_batches = load_data(data_dir+'/'+params['data'], params['batch_size'])\n",
        "    gen_data = torch.load(results_dir+'/Your_GAN/your_clf.pt')\n",
        "    sample_data = torch.load(data_dir+'/ecg_mit_nsnr.pt')\n",
        "    print('data_loaded')\n",
        "\n",
        "    # Compare 50 samples of Generated Data against 50 samples from every batch\n",
        "    # compute dtw for every batch against our generated data\n",
        "    dtw_result = (evaluate_dtw_sample(gen_data[:50,:,:], sample_data[:50,:,:]))\n",
        "    \n",
        "    return dtw_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4_REPr0zjxI"
      },
      "source": [
        "This function was used in previous work.. Not used in this work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVdu8uWHXq8V"
      },
      "source": [
        "def plot_dtw(results_dir, params, CB):\n",
        "    dtw = np.loadtxt(results_dir+'/DTW_dependent.csv', delimiter=',')\n",
        "    # Share a X axis with each column of subplots\n",
        "    fig, axes = plt.subplots(len(params['minibatch_layer']), 1, sharex='col', figsize=(10, 7))\n",
        "    plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "    epoch_range = np.arange(0, params['epochs'], 1)\n",
        "    for j in range(len(dtw)):\n",
        "        axes[j].plot(epoch_range, dtw[j][0:], c=CB[0])\n",
        "        axes[j].set_title('MBD Layer: ' + str(j))\n",
        "        axes[j].set_ylabel('DTW Value')\n",
        "    axes[4].set_xlabel('Epoch')\n",
        "    plt.savefig(results_dir+'/DTW_dependent.svg', format='svg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt1GwQWEzi-0"
      },
      "source": [
        "R Multivariate DTW package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z63XD0gxUVE"
      },
      "source": [
        "\"\"\"directories = ['LSGAN_MBD_Training', 'LSGAN_ARR_MBD_Training', \n",
        "               'SOFTDTWGAN_MBD_Training', 'SOFTDTWGAN_ARR_MBD_Training',\n",
        "               'LSGAN_lNSR-RDTW_Training', 'LSGAN_lARR-RDTW_Training',\n",
        "               'Loss-SenseGAN_NSRfdtw', 'Loss-SenseGAN_Arrfdtw',\n",
        "               'Loss-SenseGAN_Arr']\n",
        "\n",
        "files = ['nsr_45_clf.pt', 'arr_46_clf.pt',\n",
        "         'nsr_19_clf.pt', 'arr_42_clf.pt',\n",
        "         'nsr_28_clf.pt', 'arr_37_clf.pt',\n",
        "         'nsr_15_clf.pt', 'arr_43_clf.pt',\n",
        "         'arr_33_clf.pt']\"\"\"\n",
        "\n",
        "def R_DTW(clf_path, data_file, params): \n",
        "\n",
        "  fake = torch.load(clf_path)\n",
        "  real = torch.load(data_file)\n",
        "\n",
        "  dtw_dist = []\n",
        "  for i in range(200):\n",
        "    for j in range(len(fake)):\n",
        "      X = real[i,:,:].detach().cpu().numpy()\n",
        "      Y = fake[j,:,:].detach().cpu().numpy()\n",
        "\n",
        "      template = X.transpose()\n",
        "      rt,ct = template.shape\n",
        "      query = Y.transpose()\n",
        "      rq,cq = query.shape\n",
        "\n",
        "      #converting numpy matrices to R matrices\n",
        "      templateR=R.matrix(template,nrow=rt,ncol=ct)\n",
        "      queryR=R.matrix(query,nrow=rq,ncol=cq)\n",
        "\n",
        "      # Calculate the alignment vector and corresponding distance\n",
        "      alignment = R.dtw(templateR,queryR,keep=True, step_pattern=R.rabinerJuangStepPattern(4,\"c\"),open_begin=True,open_end=True)\n",
        "\n",
        "      dist = alignment.rx('distance')[0][0]\n",
        "      dtw_dist.append(dist)\n",
        "\n",
        "  return np.mean(dtw_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imyw5LFnVHDl"
      },
      "source": [
        "## Main\n",
        "\n",
        "Here we are implementing R's Mutivariate DTW (`R_DTW`) for speed of computation. You can use our DTW adaptation via `run_DTW_d_short` or `run_DTW_d` but this takes a while to execute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q1tZSrPR6KR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b211f559-a103-4f13-c8ad-7fb3e265137b"
      },
      "source": [
        "params = load_params(results_dir+'/parameters.json')\n",
        "\n",
        "clf_path = results_dir+'/Your_GAN/your_clf.pt'\n",
        "data_file = data_dir+'/ecg_mit_nsnr.pt'\n",
        "\n",
        "dtw_result = R_DTW(clf_path, data_file, params)\n",
        "#dtw = run_DTW_d_short(data_dir, results_dir, params)\n",
        "\n",
        "dtw_result = np.asarray(dtw_result)\n",
        "print(dtw_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([200, 500, 2])\n",
            "3.5474548241094386\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}